{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/justinmjoseph2/NLP3/blob/main/nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvEk3pJOjQVP"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "cmR1RDtA6_sB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YwMVxGclFrL"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "file_path = '/content/drive/My Drive/Colab Notebooks/NLP/IMDB Dataset.csv'\n",
        "df = pd.read_csv(file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cds6H5M0nEF7"
      },
      "outputs": [],
      "source": [
        "# Predefined set of common stopwords\n",
        "predefined_stopwords = {\n",
        "    'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your',\n",
        "    'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it',\n",
        "    \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this',\n",
        "    'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had',\n",
        "    'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while',\n",
        "    'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\n",
        "    'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then',\n",
        "    'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other',\n",
        "    'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just',\n",
        "    'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn',\n",
        "    \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn',\n",
        "    \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\",\n",
        "    'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcWI9FQXnyTh"
      },
      "outputs": [],
      "source": [
        "# Function to clean text with predefined stopwords\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'<br />', ' ', text)  # Remove HTML tags\n",
        "    text = re.sub(r'[^a-zA-Z]', ' ', text)  # Remove non-alphabetic characters\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = ' '.join([word for word in text.split() if word not in predefined_stopwords])  # Remove stopwords\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OdkarCPn1QG"
      },
      "outputs": [],
      "source": [
        "# Clean the reviews\n",
        "df['cleaned_review'] = df['review'].apply(clean_text)\n",
        "\n",
        "# Encode the sentiment labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['sentiment_encoded'] = label_encoder.fit_transform(df['sentiment'])\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X = df['cleaned_review']\n",
        "y = df['sentiment_encoded']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Vectorize the text using TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "print(X_train_tfidf.shape, X_test_tfidf.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3-jaA4in389"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Initialize the models\n",
        "nb_model = MultinomialNB()\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "svm_model = SVC(kernel='linear', random_state=42)\n",
        "\n",
        "# Train the models\n",
        "nb_model.fit(X_train_tfidf, y_train)\n",
        "rf_model.fit(X_train_tfidf, y_train)\n",
        "svm_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predict the test set\n",
        "y_pred_nb = nb_model.predict(X_test_tfidf)\n",
        "y_pred_rf = rf_model.predict(X_test_tfidf)\n",
        "y_pred_svm = svm_model.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate the models\n",
        "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
        "\n",
        "report_nb = classification_report(y_test, y_pred_nb, target_names=label_encoder.classes_)\n",
        "report_rf = classification_report(y_test, y_pred_rf, target_names=label_encoder.classes_)\n",
        "report_svm = classification_report(y_test, y_pred_svm, target_names=label_encoder.classes_)\n",
        "\n",
        "print(f\"Naive Bayes Accuracy: {accuracy_nb}\\n\")\n",
        "print(f\"Random Forest Accuracy: {accuracy_rf}\\n\")\n",
        "print(f\"SVM Accuracy: {accuracy_svm}\\n\")\n",
        "\n",
        "print(f\"Naive Bayes Classification Report:\\n{report_nb}\\n\")\n",
        "print(f\"Random Forest Classification Report:\\n{report_rf}\\n\")\n",
        "print(f\"SVM Classification Report:\\n{report_svm}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "muz9UYvUn-ln"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Generate confusion matrices\n",
        "conf_matrix_nb = confusion_matrix(y_test, y_pred_nb)\n",
        "conf_matrix_rf = confusion_matrix(y_test, y_pred_rf)\n",
        "conf_matrix_svm = confusion_matrix(y_test, y_pred_svm)\n",
        "\n",
        "# Plot confusion matrices\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "sns.heatmap(conf_matrix_nb, annot=True, fmt='d', cmap='Blues', ax=axes[0])\n",
        "axes[0].set_title('Naive Bayes Confusion Matrix')\n",
        "axes[0].set_xlabel('Predicted')\n",
        "axes[0].set_ylabel('True')\n",
        "\n",
        "sns.heatmap(conf_matrix_rf, annot=True, fmt='d', cmap='Blues', ax=axes[1])\n",
        "axes[1].set_title('Random Forest Confusion Matrix')\n",
        "axes[1].set_xlabel('Predicted')\n",
        "axes[1].set_ylabel('True')\n",
        "\n",
        "sns.heatmap(conf_matrix_svm, annot=True, fmt='d', cmap='Blues', ax=axes[2])\n",
        "axes[2].set_title('SVM Confusion Matrix')\n",
        "axes[2].set_xlabel('Predicted')\n",
        "axes[2].set_ylabel('True')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Compute ROC curve and AUC for each model\n",
        "fpr_nb, tpr_nb, _ = roc_curve(y_test, nb_model.predict_proba(X_test_tfidf)[:,1])\n",
        "fpr_rf, tpr_rf, _ = roc_curve(y_test, rf_model.predict_proba(X_test_tfidf)[:,1])\n",
        "fpr_svm, tpr_svm, _ = roc_curve(y_test, svm_model.decision_function(X_test_tfidf))\n",
        "\n",
        "roc_auc_nb = auc(fpr_nb, tpr_nb)\n",
        "roc_auc_rf = auc(fpr_rf, tpr_rf)\n",
        "roc_auc_svm = auc(fpr_svm, tpr_svm)\n",
        "\n",
        "# Plot ROC curves\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.plot(fpr_nb, tpr_nb, color='blue', lw=2, label=f'Naive Bayes (AUC = {roc_auc_nb:.2f})')\n",
        "plt.plot(fpr_rf, tpr_rf, color='green', lw=2, label=f'Random Forest (AUC = {roc_auc_rf:.2f})')\n",
        "plt.plot(fpr_svm, tpr_svm, color='red', lw=2, label=f'SVM (AUC = {roc_auc_svm:.2f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], color='grey', linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "SSQZsrqDt5fA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame for accuracy scores\n",
        "accuracy_data = pd.DataFrame({\n",
        "    'Model': ['Naive Bayes', 'Random Forest', 'SVM'],\n",
        "    'Accuracy': [accuracy_nb, accuracy_rf, accuracy_svm]\n",
        "})\n",
        "\n",
        "# Plot bar plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.barplot(x='Model', y='Accuracy', data=accuracy_data, palette='viridis')\n",
        "plt.ylim(0, 1)\n",
        "plt.title('Model Accuracy Comparison')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "SllyBOn7t9Au"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ceF8Yu8fukjQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}